callbacks:
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    min_delta: 0.0
    monitor: val_loss/dataloader_idx_0
    patience: 500
  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: epoch
data:
  batch_size: 32
  beat_type: tempo
  n_frames: 2048
  n_workers: 8
  path: ./gtzan/genres_original
  pin_memory: true
  valid_percent: 0.9
model:
  channels: 20
  dilations:
  - 1
  - 2
  - 4
  - 8
  - 16
  - 32
  - 64
  - 128
  - 256
  - 512
  - 1024
  dropout: 0.1
  kernel_size: 5
  mode: ${data.beat_type}
model_checkpoint:
  every_n_epochs: 5
  filename: '{epoch:02d}'
  monitor: val_loss
  save_last: true
  save_top_k: 1
optim:
  betas:
  - 0.9
  - 0.999
  lr: 0.0003
  optimizer: RAdam
  weight_decay: 0
trainer:
  accelerator: gpu
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 100
  devices:
  - 0
  fast_dev_run: false
  max_epochs: 50000
  num_sanity_val_steps: 1
  precision: 32
  profiler: false
xp_config:
  ckpt_path: ./checkpoints
  dataset: GTZAN
  model_type: BeatBockNet
